{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler('orchestrator.log')\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "\n",
    "from autogen.agentchat.contrib.orchestrator_agent import OrchestratorAgent\n",
    "from autogen.agentchat import AssistantAgent, UserProxyAgent\n",
    "import json\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": os.environ.get(\"MODEL\"),\n",
    "        \"api_key\": os.environ.get(\"API_KEY\"),\n",
    "        \"base_url\": os.environ.get(\"BASE_URL\", None)\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "    \"timeout\": 120\n",
    "}\n",
    "\n",
    "\n",
    "coder = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    system_message=\"You are a helpful AI coding assistant. You write clean, efficient code and explain your solutions clearly. Return the code to the user. Once the code is executed, and the user gives you the result, End your massage with TERMINATE when everything is done and the code works. \",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    description=\"coder. Writes and executes code to solve tasks.\",\n",
    ")\n",
    "\n",
    "\n",
    "orchestrator = OrchestratorAgent(\n",
    "    name=\"Orchestrator\",\n",
    "    llm_config=llm_config,\n",
    "    agents=[coder],\n",
    "    max_consecutive_auto_reply=10,\n",
    "    max_stalls_before_replan=3,  \n",
    "    max_replans=3, \n",
    "    return_final_answer=True,\n",
    "    description=\"An orchestrator that manages conversation flow and handles errors.\"\n",
    ")\n",
    "\n",
    "task = \"\"\"write and execute a python prints the prime numbers between 1 and 1000\"\"\"\n",
    "orchestrator.initiate_chat(message=task)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
